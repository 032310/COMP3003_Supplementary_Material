{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5cc10b8d",
   "metadata": {},
   "source": [
    "#### Install the pre-requisite library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f860a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install mlagents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e512ff1c",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1543db2e",
   "metadata": {},
   "source": [
    "In order to ensure the compatibility of the model training procress across serveral system, the environtment and the robitic agent are configured using Unity software and C# language. Then, the environment setting is build into executable file. This allows model training can perform without the need of Unity software. In the section below, each command correspound to a model training on the experiments setting discussed in the report."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b465562",
   "metadata": {},
   "source": [
    "### Experiment 1: Reinforcement learning model training on baseline environment using PPO algorithm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce784287",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mlagents-learn config/ppo/Walker.yaml --run-id=walker_ppo --env=walker_with_ppo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718544c6",
   "metadata": {},
   "source": [
    "### Experiment 2: Reinforcement learning model training on baseline environment using SAC algorithm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501a0289",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mlagents-learn config/sac/Walker.yaml --run-id=walker_sac --env=walker_with_sac"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb352c3",
   "metadata": {},
   "source": [
    "### Experiment 3: Reinforcement learning model training on baseline environment using PPO algorithm and the intergration of imitation learning algorithm (GAIL and behavioral cloning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553fdef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mlagents-learn config/ppo/Walker_imitation_learning.yaml --run-id=walker_ppo_gail_bc --env=walker_with_ppo_gail_bc "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d042384e",
   "metadata": {},
   "source": [
    "### Experiment 4: Reinforcement learning model training on baseline environement with restricted-arm agent using PPO algorithm and the intergration of imitation learning algorithm (GAIL and behavioral cloning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d4f895",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mlagents-learn config/ppo/Walker_imitation_learning.yaml --run-id=walker_with_static_arm --env=walker_with_static_arm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b4d4de",
   "metadata": {},
   "source": [
    "### Experiment 5: Reinforcement learning model training on baseline environement with extended-leg agent using PPO algorithm and the intergration of imitation learning algorithm (GAIL and behavioral cloning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82922ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mlagents-learn config/ppo/Walker_imitation_learning.yaml --run-id=walker_extended_lower_limb --env=walker_extended_lower_limb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0915b2b8",
   "metadata": {},
   "source": [
    "### Experiment 6: Reinforcement learning model training on inclined-platform environement using PPO algorithm and the intergration of imitation learning algorithm (GAIL and behavioral cloning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec697831",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mlagents-learn config/ppo/Walker_imitation_learning.yaml --run-id=walker_on_slanted_plane --env=walker_on_slanted_plane"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166fc527",
   "metadata": {},
   "source": [
    "### Experiment 7: Reinforcement learning model training on ramp-installed environement using PPO algorithm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05729345",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mlagents-learn config/ppo/Walker_sensor_imitation_learning_with_curiousity.yaml --run-id=walker_on_ramp_with_ramps --env=walker_on_plane_with_ramps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a4ddd4",
   "metadata": {},
   "source": [
    "### Experiment 8: Reinforcement learning model training on maze-like environement using PPO algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15e5651",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mlagents-learn config/ppo/Walker_sensor_imitation_learning_with_curiousity.yaml --run-id=walker_final_experiment_setting --env=walker_final_experiment_setting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cef6d89",
   "metadata": {},
   "source": [
    "# Model Inferencing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc50288",
   "metadata": {},
   "source": [
    "### Model Inferencing on Experiment 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ddca013",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mlagents-learn config/ppo/Walker.yaml --run-id=walker_ppo --env=walker_with_ppo --inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eedee122",
   "metadata": {},
   "source": [
    "### Model Inferencing on Experiment 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90142b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mlagents-learn config/sac/Walker.yaml --run-id=walker_sac --env=walker_with_sac --inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fea9f7b",
   "metadata": {},
   "source": [
    "### Model Inferencing on Experiment 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357ce6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mlagents-learn config/ppo/Walker_imitation_learning.yaml --run-id=walker_ppo_gail_bc --env=walker_with_ppo_gail_bc --inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c0ad031",
   "metadata": {},
   "source": [
    "### Model Inferencing on Experiment 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05842956",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mlagents-learn config/ppo/Walker_imitation_learning.yaml --run-id=walker_with_static_arm --env=walker_with_static_arm --inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc64f63",
   "metadata": {},
   "source": [
    "### Model Inferencing on Experiment 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00efc151",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mlagents-learn config/ppo/Walker_imitation_learning.yaml --run-id=walker_extended_lower_limb --env=walker_extended_lower_limb --inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96d8ae5",
   "metadata": {},
   "source": [
    "### Model Inferencing on Experiment 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ff582c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mlagents-learn config/ppo/Walker_imitation_learning.yaml --run-id=walker_on_slanted_plane --env=walker_on_slanted_plane --inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab366c6c",
   "metadata": {},
   "source": [
    "### Model Inferencing on Experiment 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9823a9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mlagents-learn config/ppo/Walker_sensor_imitation_learning_with_curiousity.yaml --run-id=walker_on_ramp_with_ramps --env=walker_on_plane_with_ramps --inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a82d5a",
   "metadata": {},
   "source": [
    "### Model Inferencing on Experiment 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed4927a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mlagents-learn config/ppo/Walker_sensor_imitation_learning_with_curiousity.yaml --run-id=walker_final_experiment_setting --env=walker_final_experiment_setting --inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bde94f4",
   "metadata": {},
   "source": [
    "# Loading Pre-trained Model (using my workstation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548bc069",
   "metadata": {},
   "source": [
    "In the ocassion where the error happened in the command line above due to unforseen reason, the result of the experiment can be observed simply by running the environment executable file as the pre-trained model has been baked into the file for the ease of use. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "003b6354",
   "metadata": {},
   "source": [
    "### Experiment 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ed12a9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "! start walker_with_ppo/UnityEnvironment.exe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab00272",
   "metadata": {},
   "source": [
    "### Experiment 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3afc3c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "! start walker_with_sac/UnityEnvironment.exe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbfcfafd",
   "metadata": {},
   "source": [
    "### Experiment 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3481fbec",
   "metadata": {},
   "outputs": [],
   "source": [
    "! start walker_with_ppo_gail_bc/UnityEnvironment.exe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2f53ef",
   "metadata": {},
   "source": [
    "### Experiment 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c07cd8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "! start walker_with_static_arm/UnityEnvironment.exe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff60dd4",
   "metadata": {},
   "source": [
    "### Experiment 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "52b98b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "! start walker_extended_lower_limb/UnityEnvironment.exe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b0bd5e",
   "metadata": {},
   "source": [
    "### Experiment 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d28db0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "! start walker_on_slanted_plane/UnityEnvironment.exe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "258664cc",
   "metadata": {},
   "source": [
    "### Experiment 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7450697e",
   "metadata": {},
   "outputs": [],
   "source": [
    "! start walker_on_plane_with_ramps/UnityEnvironment.exe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2152321",
   "metadata": {},
   "source": [
    "### Experiment 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8948cbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "! start walker_final_experiment_setting/UnityEnvironment.exe"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
